{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4cd7b9-bfe7-461a-bf14-b210a74acbd4",
   "metadata": {},
   "source": [
    "**WBS Codingschool, Data Science Bootcamp, Final Project, Part Data Engineering**\n",
    "\n",
    "- This Notebook is part of our final project \"DengAI\".\n",
    "- We created a Neural Network Model in order to predict Dengue cases. For that, we needed comprehensive weather data over large areas. The ECA&D provides such for the whole of Europe, sadly without offering an API. (Source: https://www.ecad.eu/dailydata/predefinedseries.php)\n",
    "- With this notebook we create a workflow that automatically downloads weather data and data about weather stations from ECA&D, processes the data and prepares output data acording to model input schema. The prepared data is saved as zip file.\n",
    "\n",
    "**To run this notebook**\n",
    "- give existing working folder as \"path\" (e.g. \"data\")\n",
    "- input name for output zip-file as \"zip_file_name\"\n",
    "- INPUTs are made in \"HELM Box\" below\n",
    "- (Choice of features within ECA&D data is (limited) possible, also for which countries (timeperiodes) the output shall be processed.)\n",
    "- Note! During workflow a 'temp' folder is created, that will be removed at the end, due to initial large download volumne. Before removal you'll be asked, if you want to delete or keep the temp folder. Please answer Y or N to finish the process.\n",
    "- Tip! You can follow progress of workflow by observing the 'temp' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5dacab-425b-436d-b7ea-3355962edf53",
   "metadata": {},
   "source": [
    "# Data Download and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc3167a-1de7-4d01-b547-92aabbe3bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp(path):\n",
    "    folder = \"temp\"\n",
    "    temp = os.path.join(path, folder)\n",
    "    if not os.path.exists(temp):\n",
    "        os.makedirs(temp)\n",
    "    else:\n",
    "        print(\"A 'temp' subfolder already exists.\")\n",
    "    return temp        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c5aea7-2cb7-4195-82a1-dcdbfe538ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_temp(temp):\n",
    "    import shutil\n",
    "    if os.path.exists(temp):\n",
    "        yn=input(\"Do you want to remove the temporary folder including downloaded raw data now (recommended)? (Y/N)\").lower()\n",
    "        if yn == \"y\":\n",
    "            shutil.rmtree(temp)\n",
    "            print(f\"Subfolder '{temp}' and its contents deleted successfully.\")\n",
    "        elif yn == \"n\":\n",
    "            print(\"The 'temp' folder including downloads and other process data remains. Thank you.\")\n",
    "        else:\n",
    "            shutil.rmtree(temp)\n",
    "            print(f\"Subfolder '{temp}' and its contents are deleted.\")\n",
    "    else:\n",
    "        print(f\"Subfolder '{temp}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe085f72-c918-4fd5-b994-9c635884e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ecad(f, temp):\n",
    "    import requests\n",
    "\n",
    "    url = f\"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_blend_{f}.zip\"\n",
    "    url_sta = f\"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_blend_station_{f}.txt\"\n",
    "    \n",
    "    tpath = os.path.join(temp, f\"eca_blend_{f}.zip\")\n",
    "    tpath_sta = os.path.join(temp, f\"eca_stations_{f}.txt\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(tpath, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download the file {file}.\")\n",
    "\n",
    "    response_sta = requests.get(url_sta)\n",
    "    if response_sta.status_code == 200:\n",
    "        with open(tpath_sta, 'wb') as file:\n",
    "            file.write(response_sta.content)\n",
    "    else:\n",
    "        print(f\"Failed to download the file {file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad728025-80df-43d2-aa11-f6771a15ceb9",
   "metadata": {},
   "source": [
    "# Process Stations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dd635b-f578-4562-b81a-563c4fb48ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stations(st):\n",
    "    st['country'] = st['country'].str.strip()\n",
    "    return(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2854da51-c5e9-4abf-805f-aa3fd6cf5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms_str):\n",
    "    degrees, minutes, seconds = map(float, dms_str[1:].split(':'))\n",
    "    decimal_degrees = degrees + (minutes / 60) + (seconds / 3600)\n",
    "    return decimal_degrees if dms_str[0] in ('+', 'N', 'E') else -decimal_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12a0175-a949-40bd-93b2-bd888467d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinates(st):\n",
    "    df = st\n",
    "    df['latitude'] = df['latitude_DMS'].apply(dms_to_decimal)\n",
    "    df['longitude'] = df['longitude_DMS'].apply(dms_to_decimal)\n",
    "    df = df[['station_id', 'station_name', 'country', 'latitude', 'longitude', 'height_m']]\n",
    "    st = df\n",
    "    return(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "068936ea-a077-4cb9-ad12-95f858f21f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stations(f, temp):\n",
    "    inpath = os.path.join(temp, f\"eca_stations_{f}.txt\")\n",
    "    outpath = os.path.join(temp, f\"{f}_stations.csv\")\n",
    "    st = pd.read_csv(inpath, sep=\",\", skiprows=19, header=None, names=[\"station_id\", \"station_name\", \"country\", \"latitude_DMS\", \"longitude_DMS\", \"height_m\"])\n",
    "    st = clean_stations(st)\n",
    "    st = st.loc[st[\"country\"].isin(countries)]\n",
    "    st = convert_coordinates(st)\n",
    "    st = st[['station_id','country','latitude','longitude','height_m']]\n",
    "    st.to_csv(outpath, index=False)\n",
    "    station_ids = st[\"station_id\"]\n",
    "    return station_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2db76-c3d0-4103-a6a8-905459bcaf99",
   "metadata": {},
   "source": [
    "# Process Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e668eb18-9426-4264-ade6-d88f0c96fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(f, fn, temp, station_ids):\n",
    "    import zipfile\n",
    "    dfs = []\n",
    "    fpath = os.path.join(temp, f\"eca_blend_{f}.zip\")\n",
    "    with zipfile.ZipFile(fpath, 'r') as z:\n",
    "        for i in z.namelist():\n",
    "            if \"STAID\" in i:\n",
    "                st_no = int(i[8:14].lstrip(\"0\"))\n",
    "                if st_no in station_ids:\n",
    "                    with z.open(i) as file:\n",
    "                        df = pd.read_csv(file, skiprows=22, header=None)\n",
    "                        df.columns = ['station_id', 'source_id', 'date', f'{f}', 'quality']\n",
    "                        df = df[['station_id', 'date', f'{f}']]\n",
    "                        dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0ea4f0-bb8b-44af-8963-550bd32da703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df[\"date\"] = pd.to_datetime(df['date'], format='%Y%m%d') \n",
    "    df = df.loc[df[\"date\"]>=\"2022-01-01\"] #input timeperiode\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cb232-dbfd-4b52-9f8b-1576c2b8c420",
   "metadata": {},
   "source": [
    "# Prepare Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3efdb3-4c8e-4bcb-8e62-5157015e3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_process(temp):\n",
    "    txpath = os.path.join(temp, \"tx_df.csv\")\n",
    "    tx = pd.read_csv(txpath)\n",
    "    tnpath = os.path.join(temp, \"tn_df.csv\")\n",
    "    tn = pd.read_csv(tnpath)\n",
    "    rrpath = os.path.join(temp, \"rr_df.csv\")\n",
    "    rr = pd.read_csv(rrpath)\n",
    "\n",
    "    # no null\n",
    "    tx = tx.loc[tx[\"tx\"] != -9999]\n",
    "    rr = rr.loc[rr[\"rr\"] != -9999]\n",
    "    tn = tn.loc[tn[\"tn\"] != -9999]\n",
    "\n",
    "    # merge features\n",
    "    df = pd.merge(\n",
    "            pd.merge(\n",
    "            tn, tx, on=[\"station_id\", \"date\"], how=\"inner\"),                             \n",
    "         rr, on=[\"station_id\", \"date\"], how=\"inner\")\n",
    "\n",
    "    # sort and rename columns\n",
    "    df = df[[\"station_id\", \"date\", \"rr\", \"tx\", \"tn\"]\n",
    "            ].rename(columns={\"station_id\":\"station_id\", \"date\":\"date\", \"rr\":\"precipitation_amt_mm\", \"tx\":\"station_max_temp_c\", \"tn\":\"station_min_temp_c\"})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b879243b-7b21-499e-89b7-87af0b9e8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_csv_zip(df, path, zpath):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zpath, 'w') as z:\n",
    "        for i in df[\"station_id\"].unique():\n",
    "            sta_df = df.loc[df[\"station_id\"]== i]\n",
    "            csv_name = f\"station_{i}.csv\"\n",
    "            csv_path = os.path.join(temp, csv_name)\n",
    "            sta_df.to_csv(csv_path, index=False)\n",
    "            z.write(csv_path, arcname=csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbd3b8-1dce-4823-a760-baf64b4e6738",
   "metadata": {},
   "source": [
    "# HELM Box  & INPUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9906d3-d513-438f-99c0-a1695ded415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove the temporary folder including downloaded raw data now? (Y/N) j\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder 'data/temp' and its contents deleted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# INPUT 1v2! <------------------------------ I N P U T: directory/path, output filename ---------------------------<\n",
    "path = \"data/\"\n",
    "zip_file_name = \"data_ready_for_model.zip\"\n",
    "\n",
    "# INPUT 2v2! <------------------------------ I N P U T: select weather features and countries ---------------------<\n",
    "features = [\"tn\", \"tx\", \"rr\"]  # tn = min Temp, tx = max Temp, rr = precipitation\n",
    "filenames = [feature.upper() for feature in features]\n",
    "countries = ['AT', 'BE']#, 'BG', 'CY', 'CZ', 'DK', 'EE', 'GR', 'HR','HU', 'IE', 'LT', 'LU', 'LV', 'MT', 'NL', 'PL', 'PT', 'RO', 'SI', 'SK','DE','SE', 'FI', 'FR', 'CZ', 'IT', 'ES']  # ISO country code alpha2\n",
    "\n",
    "# call functions\n",
    "dfs = {}\n",
    "temp = create_temp(path)\n",
    "for f, fn in zip(features, filenames):\n",
    "    download_ecad(f, temp)\n",
    "    station_ids = set_stations(f, temp)\n",
    "    df = load_data(f, fn, temp, station_ids)\n",
    "    df = clean_data(df)\n",
    "    dfs[f\"{f}_df\"] = df\n",
    "    dpath = os.path.join(temp, f\"{f}_df.csv\")\n",
    "    df.to_csv(dpath, index=False)\n",
    "df = reload_process(temp)\n",
    "zpath = os.path.join(path, zip_file_name)\n",
    "split_to_csv_zip(df, path, zpath)\n",
    "remove_temp(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d7e3d-fb09-49b9-9ac8-1ae505530e66",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfc0c8-60f3-412d-a5a5-1ecd6f744e54",
   "metadata": {},
   "source": [
    "**Data Source: https://www.ecad.eu/dailydata/predefinedseries.php**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750f3b5d-d22f-4d99-aeb0-a7edc7604298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) ...for min. Temperature\n",
    "# EUROPEAN CLIMATE ASSESSMENT & DATASET (ECA&D), file created on: 08-04-2019\n",
    "# THESE DATA CAN BE USED FOR NON-COMMERCIAL RESEARCH AND EDUCATION PROVIDED THAT THE FOLLOWING SOURCE IS ACKNOWLEDGED: \n",
    "\n",
    "# Squintu, AA, G. van der Schrier, Y. Brugnara and AMG Klein Tank. 2019. Homogenization of daily ECA\\&D temperature series\n",
    "# Int. J. of Climatol., 39, 1243-1261. doi:10.1002/joc.5874\n",
    "# Data and metadata available at http://www.ecad.eu\n",
    "\n",
    "# FILE FORMAT (MISSING VALUE CODE = -9999):\n",
    "\n",
    "# 01-06 STAID: Station identifier\n",
    "# 08-13 SOUID: Source identifier\n",
    "# 15-22 DATE : Date YYYYMMDD\n",
    "# 24-28 TN   : Minimum temperature in 0.1 &#176;C\n",
    "# 30-34 Q_TN : quality code for TN (0='valid'; 1='suspect'; 9='missing')\n",
    "\n",
    "\n",
    "# 2) ...for max. Temperature and Precipitation:\n",
    "# EUROPEAN CLIMATE ASSESSMENT & DATASET (ECA&D), file created on: 16-01-2024\n",
    "# THESE DATA CAN BE USED FOR NON-COMMERCIAL RESEARCH AND EDUCATION PROVIDED THAT THE FOLLOWING SOURCE IS ACKNOWLEDGED: \n",
    "\n",
    "# Klein Tank, A.M.G. and Coauthors, 2002. Daily dataset of 20th-century surface\n",
    "# air temperature and precipitation series for the European Climate Assessment.\n",
    "# Int. J. of Climatol., 22, 1441-1453.\n",
    "# Data and metadata available at http://www.ecad.eu\n",
    "\n",
    "# FILE FORMAT (MISSING VALUE CODE = -9999):\n",
    "\n",
    "# 01-06 STAID: Station identifier\n",
    "# 08-13 SOUID: Source identifier\n",
    "# 15-22 DATE : Date YYYYMMDD\n",
    "# 24-28 TX   : Maximum temperature in 0.1 &#176;C\n",
    "# 30-34 Q_TX : quality code for TX (0='valid'; 1='suspect'; 9='missing')\n",
    "\n",
    "# 24-28 RR   : Precipitation amount in 0.1 mm\n",
    "# 30-34 Q_RR : quality code for RR (0='valid'; 1='suspect'; 9='missing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
